{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "% matplotlib notebook\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from skimage.transform import resize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading downscaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cifar10_image(img_flat):\n",
    "    mean_pixel = [103.939, 116.779, 123.68] #mean pixels for VGG16\n",
    "    img_R = img_flat[0:1024].reshape((32, 32)) - mean_pixel[0]\n",
    "    img_G = img_flat[1024:2048].reshape((32, 32)) - mean_pixel[1]\n",
    "    img_B = img_flat[2048:3072].reshape((32, 32)) - mean_pixel[2]\n",
    "    img = np.dstack((img_R, img_G, img_B))\n",
    "    return img\n",
    "\n",
    "def extract_features(model,img,input_size=224,exit_layer = 'fc2'):\n",
    "    x = resize(img,(input_size,input_size))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    model_extractfeatures = Model(input=model.input, output=model.get_layer(exit_layer).output)\n",
    "    fc2_features = np.squeeze(model_extractfeatures.predict(x))\n",
    "    #print(fc2_features.shape)\n",
    "    #fc2_features = fc2_features.reshape((4096,1))\n",
    "    return fc2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(X, model):\n",
    "    extracted_features = np.zeros((X.shape[0],4096))\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(len(X_train)):\n",
    "        extracted_features[i] = extract_features(model,img=display_cifar10_image(X[i]))\n",
    "        if i%100 == 0:\n",
    "            print(\"{} %\".format(i/100))\n",
    "            t = time.time() - start\n",
    "            print(\"time eclipsed:\\nSeconds: {}\\nMinutes: {}\\nHours: {}\".format(t,t/60,t/3600))\n",
    "    print(\"TOTAL TIME: {}\".format(time.time()-start))\n",
    "    \n",
    "    return extracted_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = h5py.File('datasets/datatraining.h5','r')\n",
    "test = h5py.File('datasets/datatest.h5','r')\n",
    "X_train, y_train = train['data'][:], train['labels'][:]\n",
    "X_test, y_test = test['data'][:], test['labels'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = np.zeros((X_train.shape[0],4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "f = FloatProgress(min=0, max=len(X_train))\n",
    "display(f)\n",
    "for i in range(len(X_train)):\n",
    "    extracted_features[i] = extract_features(model,img=display_cifar10_image(X_train[i]))\n",
    "    f.value+=1\n",
    "    if i%100 == 0:\n",
    "        print(\"{} %\".format(i/100))\n",
    "        t = time.time() - start\n",
    "        print(\"time eclipsed:\\nSeconds: {}\\nMinutes: {}\\nHours: {}\".format(t,t/60,t/3600))\n",
    "print(\"TOTAL TIME: {}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('extracted_tsne.h5', 'w')\n",
    "h5f.create_dataset('extracted_data', data=extracted_features)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_test = np.zeros((X_test.shape[0],4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FloatProgress(min=0, max=len(X_test))\n",
    "display(f)\n",
    "for i in range(len(X_train)):\n",
    "    extracted_features_test[i] = extract_features(model,img=display_cifar10_image(X_test[i]))\n",
    "    f.value+=1\n",
    "    if i%100 == 0:\n",
    "        print(\"{} %\".format(i/10))\n",
    "        t = time.time() - start\n",
    "        print(\"time eclipsed:\\nSeconds: {}\\nMinutes: {}\\nHours: {}\".format(t,t/60,t/3600))\n",
    "print(\"TOTAL TIME: {}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('extracted_tsne_test.h5', 'w')\n",
    "h5f.create_dataset('extracted_data', data=extracted_features_test)\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
